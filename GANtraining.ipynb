{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importando o módulo .py com o Generator e Discriminator\n",
    "from gan import Discriminator, Generator  # Substitua 'seu_arquivo' pelo nome do arquivo .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   carbon_concentration_per_weight  silicon_concentration_per_weight  \\\n",
      "0                         0.041382                          0.321143   \n",
      "1                         0.082378                         -0.821959   \n",
      "2                        -0.083932                          0.216021   \n",
      "3                         1.266667                          0.424351   \n",
      "4                         0.242557                         -0.456118   \n",
      "\n",
      "   manganese_concentration_per_weight  sulphur_concentration_per_weight  \\\n",
      "0                           -0.922977                          1.830136   \n",
      "1                            0.353442                          0.263364   \n",
      "2                            0.117702                         -0.305449   \n",
      "3                            1.777874                          0.263364   \n",
      "4                            0.412394                          0.000000   \n",
      "\n",
      "   phosphorus_concentration_per_weight  nickel_concentration_per_weight  \\\n",
      "0                             0.682994                        -0.562371   \n",
      "1                            -0.783466                        -0.738607   \n",
      "2                            -0.338087                         0.314329   \n",
      "3                             0.136022                         0.366649   \n",
      "4                            -0.783466                        -0.738607   \n",
      "\n",
      "   hromium_concentration_per_weight  olybdenum_concentration_per_weight  \\\n",
      "0                          0.577983                            0.762285   \n",
      "1                         -0.529371                            0.450500   \n",
      "2                          0.484108                            0.130690   \n",
      "3                          0.308296                           -0.576936   \n",
      "4                          0.371105                           -0.590616   \n",
      "\n",
      "   anadium_concentration_per_weight  copper_concentration_per_weight  ...  \\\n",
      "0                          0.866869                        -0.456025  ...   \n",
      "1                         -0.470363                        -0.825097  ...   \n",
      "2                          0.039304                         0.855607  ...   \n",
      "3                         -0.164568                         0.909261  ...   \n",
      "4                         -0.470363                        -0.825097  ...   \n",
      "\n",
      "     UMAP_2    UMAP_3    UMAP_4    UMAP_5    UMAP_6    UMAP_7  group_2  \\\n",
      "0 -0.515045  0.397269 -0.930660  1.126555 -0.502379 -0.824251      0.0   \n",
      "1  0.056008  0.007753  1.394342  0.622910  0.057236 -0.015176     -1.0   \n",
      "2  0.201095  0.782714 -0.036300 -0.861656 -0.100070 -0.366794      0.0   \n",
      "3  0.303129  0.580175 -0.098842  1.381154  1.373695  0.862518      0.0   \n",
      "4  0.052640  0.012854  1.390787  0.631856  0.057913 -0.001160     -1.0   \n",
      "\n",
      "   group_3  group_4  group_5  \n",
      "0      0.0      0.0      0.0  \n",
      "1      0.0     -1.0      0.0  \n",
      "2      0.0      0.0      0.0  \n",
      "3      0.0      0.0     -1.0  \n",
      "4      0.0     -1.0      0.0  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "target_features=[\"yield_strength\",\n",
    "\"ultimate_tensile_strength\",]\n",
    "\n",
    "target = target_features[0]\n",
    "\n",
    "X_train = pd.read_csv('processed_data/knn/processed_train_knn.csv')\n",
    "y_train = pd.read_csv('data/train.csv')\n",
    "y_train = y_train[target]\n",
    "\n",
    "X_valid = pd.read_csv('processed_data/knn/processed_validation_knn.csv')\n",
    "y_valid = pd.read_csv('data/validation.csv')\n",
    "y_valid = y_valid[target]\n",
    "\n",
    "X_test = pd.read_csv('processed_data/knn/processed_test_knn.csv')\n",
    "y_test = pd.read_csv('data/test.csv')\n",
    "y_test = y_test[target]\n",
    "\n",
    "print(X_train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1      False\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "243    False\n",
       "244     True\n",
       "245     True\n",
       "246    False\n",
       "247     True\n",
       "Name: yield_strength, Length: 248, dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/150 - Loss D: 0.682395875453949, Loss G: 0.710929811000824\n",
      "Epoch 10/150 - Loss D: 0.9691396355628967, Loss G: 0.4184715747833252\n",
      "Epoch 20/150 - Loss D: 0.6626369953155518, Loss G: 0.8682767152786255\n",
      "Epoch 30/150 - Loss D: 0.5845738649368286, Loss G: 0.7712709307670593\n",
      "Epoch 40/150 - Loss D: 0.6291539072990417, Loss G: 0.7660590410232544\n",
      "Epoch 50/150 - Loss D: 0.6940709352493286, Loss G: 0.7642236351966858\n",
      "Epoch 60/150 - Loss D: 0.7006665468215942, Loss G: 0.6411969661712646\n",
      "Epoch 70/150 - Loss D: 0.6931097507476807, Loss G: 0.7931127548217773\n",
      "Epoch 80/150 - Loss D: 0.6161899566650391, Loss G: 0.8124905228614807\n",
      "Epoch 90/150 - Loss D: 0.6493948698043823, Loss G: 0.7976003885269165\n",
      "Epoch 100/150 - Loss D: 0.6933438181877136, Loss G: 0.7570127248764038\n",
      "Epoch 110/150 - Loss D: 0.6333661079406738, Loss G: 0.8595978021621704\n",
      "Epoch 120/150 - Loss D: 0.6797140836715698, Loss G: 0.8967921137809753\n",
      "Epoch 130/150 - Loss D: 0.5573831796646118, Loss G: 0.7976824045181274\n",
      "Epoch 140/150 - Loss D: 0.6449071168899536, Loss G: 0.7149957418441772\n"
     ]
    }
   ],
   "source": [
    "# Dividindo o dataset em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "generator = Generator(size = X_train.shape[1])  # Tamanho baseado no número de features\n",
    "discriminator = Discriminator(size = X_train.shape[1])\n",
    "\n",
    "# X são as features e y é a coluna alvo 'Yield strength'\n",
    "# Convertendo os dados em tensores\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Definindo otimizadores\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.00005)\n",
    "\n",
    "# Função de perda\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Função de treinamento da GAN (mesma de antes)\n",
    "def train_GAN(epochs=10000, print_every=1000):\n",
    "    for epoch in range(epochs):\n",
    "        for real_data, _ in train_loader:  # Itera sobre batches\n",
    "            # Gerar ruído\n",
    "            z = torch.randn(real_data.size(0), real_data.size(1))  # Ruído no formato das features\n",
    "            \n",
    "            # Gerar amostras falsas (saídas do generator)\n",
    "            fake_data = generator(z)\n",
    "            \n",
    "            # Treinando o Discriminator\n",
    "            real_preds = discriminator(real_data)\n",
    "            fake_preds = discriminator(fake_data.detach())\n",
    "            \n",
    "            # Definindo rótulos\n",
    "            real_labels = torch.ones(real_data.size(0), 1) * 0.9 \n",
    "            fake_labels = torch.zeros(real_data.size(0), 1) + 0.1 \n",
    "            \n",
    "            # Calculando a perda do Discriminator\n",
    "            loss_real = criterion(real_preds, real_labels)\n",
    "            loss_fake = criterion(fake_preds, fake_labels)\n",
    "            loss_D = (loss_real + loss_fake) / 2\n",
    "            \n",
    "            # Otimizando o Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # Treinando o Generator\n",
    "            fake_preds = discriminator(fake_data)\n",
    "            loss_G = criterion(fake_preds, real_labels)  # O generator quer enganar o discriminator\n",
    "            \n",
    "            # Otimizando o Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "        \n",
    "        # Exibir o progresso\n",
    "        if epoch % print_every == 0:\n",
    "            print(f'Epoch {epoch}/{epochs} - Loss D: {loss_D.item()}, Loss G: {loss_G.item()}')\n",
    "\n",
    "# Treinar a GAN\n",
    "train_GAN(epochs=150, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_true: (248, 42)\n",
      "Shape of y_pred: (248, 42)\n",
      "Shape of y_true_cleaned: (248, 42)\n",
      "Shape of y_pred_cleaned: (248, 42)\n",
      "MSE: 13.97876262664795, MAE: 0.9396845698356628, R²: -0.3035505060254361\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do Generator após o treino\n",
    "with torch.no_grad():\n",
    "    z_test = torch.randn(X_test_tensor.size(0), X_test_tensor.size(1))  # Gerar ruído para o conjunto de teste\n",
    "    generated_data = generator(z_test) #ultuma linha é o y\n",
    "\n",
    "# Comparar os resultados gerados com o conjunto de teste real\n",
    "y_pred = generated_data.numpy()\n",
    "y_true = X_test_tensor.numpy()\n",
    "print(f'Shape of y_true: {y_true.shape}')\n",
    "print(f'Shape of y_pred: {y_pred.shape}')\n",
    "nan_indices = np.isnan(y_true).flatten()  # Obter um array booleano indicando onde estão os NaNs\n",
    "\n",
    "# Remover as linhas correspondentes em y_true e y_pred\n",
    "y_true_cleaned = y_true[~nan_indices]  # Mantém apenas as linhas onde não há NaNs\n",
    "y_pred_cleaned = y_pred[~nan_indices]  # Remove as mesmas linhas em y_pred\n",
    "\n",
    "# Exibir as novas formas para confirmar a remoção correta\n",
    "print(f'Shape of y_true_cleaned: {y_true_cleaned.shape}')\n",
    "print(f'Shape of y_pred_cleaned: {y_pred_cleaned.shape}')\n",
    "\n",
    "# Agora você pode calcular as métricas usando y_true_cleaned e y_pred_cleaned\n",
    "mse = mean_squared_error(y_true_cleaned, y_pred_cleaned[:, -1])\n",
    "mae = mean_absolute_error(y_true_cleaned, y_pred_cleaned[:, -1])\n",
    "r2 = r2_score(y_true_cleaned, y_pred_cleaned[:, -1])\n",
    "\n",
    "print(f'MSE: {mse}, MAE: {mae}, R²: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
